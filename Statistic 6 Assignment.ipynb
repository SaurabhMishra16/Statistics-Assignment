{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4551eb6-c963-4838-8c28-0f01c8914816",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82e1d9-86d1-4294-8ef0-c75581319119",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare means between multiple groups or treatments. It tests the null hypothesis that there is no significant difference among the means of the groups being compared. ANOVA is based on several assumptions, and violations of these assumptions can impact the validity of the results. The main assumptions for using ANOVA are:\n",
    "\n",
    "1. **Independence:** The observations within each group are independent of each other. This means that the values in one group are not related to or influenced by the values in another group.\n",
    "\n",
    "2. **Normality:** The data within each group follow a normal distribution. This assumption is especially important when the sample sizes are small. Departures from normality can impact the accuracy of p-values and confidence intervals.\n",
    "\n",
    "3. **Homogeneity of Variance (Homoscedasticity):** The variances of the different groups are roughly equal. In other words, the variability within each group is similar across all groups. Violations of homogeneity of variance can affect the validity of F-test results.\n",
    "\n",
    "Examples of violations and their potential impacts:\n",
    "\n",
    "1. **Independence Violation:** If observations within groups are not independent, the assumption is violated. For instance, in a longitudinal study where repeated measurements are taken on the same subjects, the observations within each subject may be correlated. Violations can lead to inaccurate p-values and confidence intervals.\n",
    "\n",
    "2. **Normality Violation:** If the data are not normally distributed within each group, the ANOVA results might be inaccurate. For instance, if the data is heavily skewed or contains outliers, the normality assumption might be violated. This can lead to inflated or deflated type I error rates.\n",
    "\n",
    "3. **Homoscedasticity Violation:** When the assumption of homogeneity of variance is violated, the F-test's validity may be compromised. If the variances are not equal across groups, the power of the test may be affected, leading to the potential for false positive or false negative results.\n",
    "\n",
    "In the presence of these violations, it's important to consider alternative analysis methods or transformations of the data to address the issues. Additionally, robust statistical techniques that are less sensitive to these assumptions may be employed.\n",
    "\n",
    "Ultimately, when planning and interpreting ANOVA, it's crucial to be aware of the assumptions, assess whether they are met, and address violations appropriately to ensure the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a26c31-4c91-4a14-9c88-9a6efb9ea436",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f1599-4059-4b9a-95aa-3ee788385ffd",
   "metadata": {},
   "source": [
    "There are three main types of ANOVA (Analysis of Variance), each designed to handle different experimental or study designs and research questions:\n",
    "\n",
    "1. **One-Way ANOVA:** One-Way ANOVA is used when you have a single independent variable with three or more levels (groups) and you want to compare means across these groups. It helps determine if there are statistically significant differences in means between the groups.\n",
    "\n",
    "   Example: A pharmaceutical company wants to test the effectiveness of three different doses of a new drug by measuring the blood pressure reduction in patients.\n",
    "\n",
    "2. **Two-Way ANOVA:** Two-Way ANOVA is used when you have two independent variables (factors) and you want to assess their effects on a dependent variable. It explores interactions between these two factors in addition to their individual effects.\n",
    "\n",
    "   Example: An educational researcher wants to investigate whether a new teaching method and the gender of students have a significant impact on exam scores. Both teaching method and gender are considered as factors in the ANOVA.\n",
    "\n",
    "3. **Repeated Measures ANOVA:** Repeated Measures ANOVA is used when you have a repeated measurement or matched pairs design, where the same subjects are measured under different conditions or at multiple time points. It assesses the effects of a within-subject factor (repeated measurements) on a dependent variable.\n",
    "\n",
    "   Example: A psychologist wants to study the effects of a therapy on anxiety levels in a group of individuals. Anxiety levels are measured before the therapy, after one month of therapy, and after three months of therapy for each individual.\n",
    "\n",
    "It's important to choose the appropriate type of ANOVA based on your experimental design and research question. One-Way ANOVA is suitable when you have one independent variable with multiple levels, Two-Way ANOVA is used when you have two independent variables, and Repeated Measures ANOVA is employed for within-subjects designs with repeated measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f8bba-777f-499e-90dc-fd6907a8a612",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597af69-e938-4d9e-b9c6-6c73906f21f1",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variability in a dataset into different sources of variation. It helps to understand how much of the total variability can be attributed to different factors or sources in the study, such as group differences, error, and interactions between factors. This concept is crucial in ANOVA because it provides insights into the relative contributions of different sources of variation to the overall variability observed in the data.\n",
    "\n",
    "In a typical ANOVA context, the total variability in the data is partitioned into the following components:\n",
    "\n",
    "1. **Between-Group Variability (SSB):** This represents the variability among the group means. It measures how much the means of the different groups differ from each other. The larger the between-group variability, the more evidence there is for a significant difference among the group means.\n",
    "\n",
    "2. **Within-Group Variability (SSW or SSE):** This represents the variability within each group. It measures the random variability within each group, also known as error or residual variability. It represents the differences within groups that are not explained by the factors being studied.\n",
    "\n",
    "3. **Total Variability (SST):** This represents the total variability in the dataset. It's the sum of the between-group and within-group variabilities. It serves as a reference point to compare how much variability is accounted for by the factors under study.\n",
    "\n",
    "The partitioning of variance is important for several reasons:\n",
    "\n",
    "1. **Interpretation of Results:** By understanding the partitioning of variance, researchers can interpret the relative importance of the factors being studied. For example, if the between-group variability is much larger than the within-group variability, it suggests that the factor being studied has a significant impact.\n",
    "\n",
    "2. **Assessment of Effects:** It helps researchers assess the significance of group differences or treatment effects. If the between-group variability is significantly larger than the within-group variability, it suggests that the factor being studied has a significant effect on the outcome.\n",
    "\n",
    "3. **Model Validation:** Understanding the partitioning of variance can help validate the statistical model used in the analysis. If the majority of the variability is explained by the factors of interest, the model is likely a good fit to the data.\n",
    "\n",
    "4. **Experimental Design:** It helps researchers design experiments by considering the sources of variability that need to be controlled or minimized.\n",
    "\n",
    "Overall, the partitioning of variance in ANOVA provides a structured approach to understanding the relationships between different sources of variation and their influence on the study's outcomes. It guides researchers in drawing meaningful conclusions from their data and making informed decisions based on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2823408-afb3-4a4a-89b2-f3627cec1e38",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f216f0-20ad-45aa-9910-fdfecffe510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 82.83333333333334\n",
      "SSE: 74.33333333333333\n",
      "SSR: 8.500000000000014\n",
      "F-statistic: 13.117647058823508\n",
      "p-value: 0.03287158770035081\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create a sample dataset (replace this with your actual data)\n",
    "data = {'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "        'response': [10, 12, 15, 18, 7, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = df['response'].mean()\n",
    "\n",
    "# Calculate the sum of squares total (SST)\n",
    "df['deviation_squared'] = (df['response'] - overall_mean) ** 2\n",
    "SST = df['deviation_squared'].sum()\n",
    "\n",
    "# Calculate group means\n",
    "group_means = df.groupby('group')['response'].mean()\n",
    "\n",
    "# Calculate the sum of squares explained (SSE)\n",
    "SSE = np.sum((group_means - overall_mean) ** 2 * df['group'].value_counts())\n",
    "\n",
    "# Calculate the sum of squares residual (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "# Degrees of freedom\n",
    "df_total = len(df) - 1\n",
    "df_group = len(group_means) - 1\n",
    "df_residual = df_total - df_group\n",
    "\n",
    "# Mean squares\n",
    "MS_group = SSE / df_group\n",
    "MS_residual = SSR / df_residual\n",
    "\n",
    "# F-statistic\n",
    "F_statistic = MS_group / MS_residual\n",
    "\n",
    "# p-value\n",
    "p_value = 1 - stats.f.cdf(F_statistic, df_group, df_residual)\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8b09b-e4a6-4ca2-86e8-39630fb91fe9",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b71d9a7-2358-46b5-adec-b79709daed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A: 28.166666666666636\n",
      "Main Effect B: 1.333333333333331\n",
      "Interaction Effect: 8.333333333333314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset (replace this with your actual data)\n",
    "data = {'factor_A': ['A', 'A', 'B', 'B', 'A', 'B'],\n",
    "        'factor_B': ['X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "        'response': [10, 12, 15, 18, 7, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "model = ols('response ~ factor_A * factor_B', data=df).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract main effects and interaction effects from the ANOVA table\n",
    "main_effect_A = anova_table.loc['factor_A', 'sum_sq'] / anova_table.loc['factor_A', 'df']\n",
    "main_effect_B = anova_table.loc['factor_B', 'sum_sq'] / anova_table.loc['factor_B', 'df']\n",
    "interaction_effect = anova_table.loc['factor_A:factor_B', 'sum_sq'] / anova_table.loc['factor_A:factor_B', 'df']\n",
    "\n",
    "print(\"Main Effect A:\", main_effect_A)\n",
    "print(\"Main Effect B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81486b59-b551-46ed-b8cc-0a581b4363a8",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f66a02-619b-499a-a457-d5dfdb22788b",
   "metadata": {},
   "source": [
    "In a one-way Analysis of Variance (ANOVA), the F-statistic is used to test the null hypothesis that the means of multiple groups are equal. A low p-value indicates that there is strong evidence against the null hypothesis, suggesting that at least one group mean is different from the others. Let's interpret the results you provided:\n",
    "\n",
    "1. F-Statistic: 5.23\n",
    "2. P-value: 0.02\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The F-statistic of 5.23 indicates that there is some variability between the group means compared to the variability within the groups. In other words, the differences in means are not just due to random chance. However, to draw a meaningful conclusion, we need to consider the p-value.\n",
    "\n",
    "The p-value of 0.02 is below the typical significance level of 0.05 (5%). This means that the probability of observing such extreme differences in group means, assuming the null hypothesis of equal group means is true, is only 0.02 or 2%. Since the p-value is below the significance level, we reject the null hypothesis.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Based on the F-statistic and the p-value, we can conclude that there are statistically significant differences between at least some of the groups. In other words, not all group means are equal. However, the one-way ANOVA itself doesn't tell us which specific groups are different from each other – it only indicates that there are differences somewhere among the groups.\n",
    "\n",
    "To further explore the differences between specific groups, you might consider post hoc tests (e.g., Tukey's HSD, Bonferroni correction) to determine which groups are significantly different from each other. These tests help identify pairwise differences among the groups that contribute to the significant overall ANOVA result.\n",
    "\n",
    "Remember that while statistical significance suggests that the differences are unlikely due to random chance, it doesn't necessarily indicate the practical or meaningful significance of those differences. The interpretation should always be made in the context of the specific study and domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19fc6d9-a356-4567-bbac-8e66bb359522",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b931c-bf0b-41a1-b65e-1c6d89b2ded3",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA (or any statistical analysis) is an important consideration to ensure the validity and reliability of your results. There are various methods to handle missing data, each with its own potential consequences. Here's how you can handle missing data in a repeated measures ANOVA and the potential consequences of using different methods:\n",
    "\n",
    "**1. Listwise Deletion (Complete Case Analysis):**\n",
    "This method involves excluding participants with any missing data from the analysis. While it's straightforward, it can lead to reduced sample size and potential bias if the missingness is related to the variables being studied.\n",
    "\n",
    "**2. Pairwise Deletion (Available Case Analysis):**\n",
    "In this method, you use all available data for each pair of variables. This can lead to imbalanced data and biased estimates if the missingness pattern is not random.\n",
    "\n",
    "**3. Imputation Methods:**\n",
    "Imputation involves filling in missing values with estimated values. Common imputation methods include mean imputation (replacing missing values with the mean of the variable), regression imputation (predicting missing values based on other variables), and more advanced methods like multiple imputation.\n",
    "\n",
    "**Potential Consequences of Different Methods:**\n",
    "\n",
    "1. **Listwise Deletion:**\n",
    "   - Consequence: Reduced sample size, potential bias if missingness is not random.\n",
    "   - Consideration: This method is simple but can lead to loss of valuable data.\n",
    "\n",
    "2. **Pairwise Deletion:**\n",
    "   - Consequence: Imbalanced data, potentially biased estimates.\n",
    "   - Consideration: This method might be used when the missing data is not related to the variables under study, but it can still introduce bias if the missingness is systematic.\n",
    "\n",
    "3. **Imputation Methods:**\n",
    "   - Consequence: Potentially introduces artificial variability, underestimates standard errors.\n",
    "   - Consideration: Imputation methods assume that the missing data mechanism is ignorable and may introduce uncertainty into the analysis. The accuracy of imputed values depends on the model used and the assumptions made.\n",
    "\n",
    "4. **Mixed Models (Longitudinal Data Analysis):**\n",
    "   - Instead of explicitly handling missing data, mixed models (also known as hierarchical linear models or linear mixed-effects models) can incorporate subjects with missing data by using all available data in a way that respects the underlying correlation structure. This approach can provide unbiased estimates under the missing at random assumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a020f59-9476-4e84-88eb-c7ec098699c0",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44876a98-ce51-44c3-af4c-8497219e2a9b",
   "metadata": {},
   "source": [
    "Certainly, I'd be happy to elaborate further on common post-hoc tests used after ANOVA and provide examples of when to use each one:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD):**\n",
    "   - **When to use:** Tukey's HSD is a widely used post-hoc test that's appropriate when you have conducted an ANOVA and found a significant difference among group means. It helps identify which specific pairs of groups have significantly different means.\n",
    "   - **Example:** Imagine you're studying the effectiveness of three different diets on weight loss. After performing an ANOVA and finding a significant difference in weight loss among the diets, you can use Tukey's HSD to determine which pairs of diets are significantly different from each other.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **When to use:** The Bonferroni correction is applied when you are conducting multiple pairwise comparisons after ANOVA. It helps control the overall Type I error rate by adjusting the significance level for each comparison.\n",
    "   - **Example:** Let's say you're comparing the performance of five different marketing strategies on sales. To avoid inflating the chance of making a Type I error, you might use the Bonferroni correction when performing multiple pairwise comparisons.\n",
    "\n",
    "3. **Dunn's Test (Non-parametric):**\n",
    "   - **When to use:** Dunn's test is useful when the assumptions of normality and homogeneity of variances are violated. It's a non-parametric alternative to post-hoc tests like Tukey's HSD.\n",
    "   - **Example:** Suppose you're comparing the impact of three different exercise routines on endurance. If the data distribution is not normal, Dunn's test can be a suitable option for identifying differences between the routines.\n",
    "\n",
    "4. **Scheffé Test:**\n",
    "   - **When to use:** The Scheffé test is employed when you want a more powerful method that accounts for unequal group sizes or non-homogeneous variances while controlling the overall Type I error rate.\n",
    "   - **Example:** Let's say you're analyzing the performance of students from various schools on a standardized test. If the schools have different numbers of students and potentially different variability, the Scheffé test might be appropriate.\n",
    "\n",
    "5. **Fisher's Least Significant Difference (LSD):**\n",
    "   - **When to use:** Fisher's LSD is less conservative than some other methods like Tukey's HSD, and it's used when you want to minimize the chances of missing a significant difference between two groups.\n",
    "   - **Example:** Imagine you're examining the effect of three different training methods on employees' productivity. If you're more concerned about missing a real difference than making a Type I error, Fisher's LSD might be a suitable choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e532ed-b32d-4364-b977-de6c5b05d052",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd428543-1020-4b25-835a-7c9a8bab5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.0700987808557056\n",
      "p-value: 0.12983601124058824\n",
      "There is no significant difference between the mean weight loss of the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate example weight loss data for three diets\n",
    "np.random.seed(42)  # For reproducibility\n",
    "diet_A = np.random.normal(5, 1, 50)  # Mean weight loss of 5 kg with standard deviation of 1 kg\n",
    "diet_B = np.random.normal(4.8, 0.8, 50)  # Mean weight loss of 4.8 kg with standard deviation of 0.8 kg\n",
    "diet_C = np.random.normal(4.5, 1.2, 50)  # Mean weight loss of 4.5 kg with standard deviation of 1.2 kg\n",
    "\n",
    "# Combine the data for ANOVA\n",
    "all_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create corresponding group labels\n",
    "groups = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the mean weight loss of the diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c4a5f-e3d5-4d24-a406-9bb0758579fc",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7deeda63-c096-4164-b1a5-31b297f7a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      df      sum_sq    mean_sq         F  \\\n",
      "software_programs                    2.0    8.918772   4.459386  0.188810   \n",
      "experience_level                     1.0    3.262123   3.262123  0.138118   \n",
      "software_programs:experience_level   2.0   16.774440   8.387220  0.355113   \n",
      "Residual                            24.0  566.842216  23.618426       NaN   \n",
      "\n",
      "                                      PR(>F)  \n",
      "software_programs                   0.829162  \n",
      "experience_level                    0.713420  \n",
      "software_programs:experience_level  0.704716  \n",
      "Residual                                 NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)\n",
    "n = 30  # Number of employees\n",
    "software_programs = np.random.choice(['A', 'B', 'C'], size=n)\n",
    "experience_level = np.random.choice(['novice', 'experienced'], size=n)\n",
    "completion_time = np.random.normal(30, 5, size=n)  # Mean completion time of 30 with SD of 5\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'software_programs': software_programs,\n",
    "        'experience_level': experience_level,\n",
    "        'completion_time': completion_time}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert categorical variables to category data type\n",
    "df['software_programs'] = df['software_programs'].astype('category')\n",
    "df['experience_level'] = df['experience_level'].astype('category')\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('completion_time ~ software_programs * experience_level', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8578c88-715d-4746-a38d-c20210fc8809",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7131580d-ca45-4308-aa0d-033d7538ebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -5.241452601007623\n",
      "p-value: 4.066577789338641e-07\n",
      "There is a significant difference in test scores between the two groups.\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "control experimental   6.2169   0.0 3.8779 8.5559   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)\n",
    "n = 100  # Number of students\n",
    "control_scores = np.random.normal(75, 10, size=n)  # Mean score of 75 with SD of 10\n",
    "experimental_scores = np.random.normal(80, 8, size=n)  # Mean score of 80 with SD of 8\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'group': ['control'] * n + ['experimental'] * n,\n",
    "        'scores': np.concatenate([control_scores, experimental_scores])}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "control_group = df[df['group'] == 'control']['scores']\n",
    "experimental_group = df[df['group'] == 'experimental']['scores']\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if results are significant\n",
    "if p_value < 0.05:\n",
    "    mc = MultiComparison(df['scores'], df['group'])\n",
    "    result = mc.tukeyhsd()\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deab568-0e28-4e3e-bf34-5deeda5ad7f8",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87a5bb7-d9fa-4259-9416-652ec36ad37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 13.9684708766556\n",
      "p-value: 5.483947261157389e-06\n",
      "There is a significant difference in daily sales between the stores.\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      "group1 group2  meandiff p-adj    lower    upper   reject\n",
      "--------------------------------------------------------\n",
      "     A      B -104.7333 0.0208 -196.2692 -13.1974   True\n",
      "     A      C   98.1333 0.0327    6.5974 189.6692   True\n",
      "     B      C  202.8667    0.0  111.3308 294.4026   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)\n",
    "days = 30  # Number of days\n",
    "store_A_sales = np.random.randint(1000, 1500, days)\n",
    "store_B_sales = np.random.randint(900, 1400, days)\n",
    "store_C_sales = np.random.randint(1100, 1600, days)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'store': ['A'] * days + ['B'] * days + ['C'] * days,\n",
    "        'sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales])}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "anova_result = stats.f_oneway(df[df['store'] == 'A']['sales'],\n",
    "                              df[df['store'] == 'B']['sales'],\n",
    "                              df[df['store'] == 'C']['sales'])\n",
    "\n",
    "print(\"F-statistic:\", anova_result.statistic)\n",
    "print(\"p-value:\", anova_result.pvalue)\n",
    "\n",
    "if anova_result.pvalue < 0.05:\n",
    "    print(\"There is a significant difference in daily sales between the stores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in daily sales between the stores.\")\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if results are significant\n",
    "if anova_result.pvalue < 0.05:\n",
    "    tukey_result = pairwise_tukeyhsd(df['sales'], df['store'])\n",
    "    print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474e9a3-6e0b-4b5c-9f9d-694bd59ed1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
